{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP - natural language processing, extract the linguistics information from underlying data\n",
    "# it enables computers to derive meaning from human or natural language input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2176441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing tons of data\n",
    "# Applying quantitative analysis\n",
    "# 6500 languages and dilect, identifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98389c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP full automation through python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3142d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP terminologies\n",
    "# 1. Word Boundaries - determines ending of one word and begining of another\n",
    "# 2. Toeknization - technique to Split words, phrases and idioms\n",
    "# 3. Stemming - map words to their stem or root, useful in finding synonyms and extensively used in search engine\n",
    "# 4. Tf-idf - how important a word is to a document or corpus\n",
    "# 5. Semantic analytics - a technique in vectorial semantics to derive a relationship between a set of document\n",
    "# compares words, phrases, and idioms in a set of documents to extract meaning.\n",
    "# 6. Disambiguation - Intent of the word, Determines meaning and sense of words(context vs intent)\n",
    "# 7. Topic models - Discover Topics in a Collection of Documents\n",
    "\n",
    "# NLP approach for analyze Text Data\n",
    "# 1. conduct basic text processing, extract basic context of the text. eg. religious or not etc.\n",
    "# 2. categorizing and tagging words, finding lexical category and automatically tagging each word with \n",
    "# 3. for example, tag a word using languages such as chinese, spanish or ajectives nouns pronouns etc.\n",
    "# 4. classify text, feature of language and classify it eg sports, politics \n",
    "# 5. extract information in a structured way example - date, time, money, and direction\n",
    "# 6. Analyze sentence structure - capture formal grammer, find well formed or illformed structure\n",
    "# 7. Build feature based structure - insight into grammatical category, text feature based on speech tag\n",
    "# 8. Perform quantitative analysis, find entities in data and derieve raltionship among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e56f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "# select corpus, collections and models\n",
    "# stop_words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f45d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform sentence analysis\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# stop words usually have little lexical meaning I, me, myself, we, our, ours, you and so on\n",
    "stopwords.words(\"english\")[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910c8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'This is my first test string. Wow!! we are doing just fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34471b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punctuation = [char for char in sentence if char not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4aecc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'i', 's', ' ', 'i', 's', ' ', 'm', 'y', ' ', 'f', 'i', 'r', 's', 't', ' ', 't', 'e', 's', 't', ' ', 's', 't', 'r', 'i', 'n', 'g', ' ', 'W', 'o', 'w', ' ', 'w', 'e', ' ', 'a', 'r', 'e', ' ', 'd', 'o', 'i', 'n', 'g', ' ', 'j', 'u', 's', 't', ' ', 'f', 'i', 'n', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef5ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my first test string Wow we are doing just fine'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuations = ''.join(no_punctuation)\n",
    "no_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5ae861",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punctuations = no_punctuations.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d7a2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence = [word for word in no_punctuations if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8be506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'test', 'string', 'Wow', 'fine']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f571c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Application, \n",
    "# translation\n",
    "# speech recognition\n",
    "# sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
